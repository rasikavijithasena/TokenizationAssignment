{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_tokenizer = RegexpTokenizer(\"[\\w']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace_tokenizer = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweeter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Fraudster', 'Monsef', 'avoiding', 'deportation', 'from', 'Canada', '.', '#cdnpoli', '#LPC', '#CPCLDR', '�', '�', '_', 'https://t.co/ZOZOSe1CqQ', '#immigration', '#integration', '#canada', 'https://t.co/M5cKGyvV8F']\n"
     ]
    }
   ],
   "source": [
    "data = \"Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada. #cdnpoli #LPC #CPCLDR��_ https://t.co/ZOZOSe1CqQ \\n #immigration #integration #canada https://t.co/M5cKGyvV8F\"\n",
    "print(tweet_tokenizer.tokenize(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Fraudster', 'Monsef', 'avoiding', 'deportation', 'from', 'Canada', 'cdnpoli', 'LPC', 'CPCLDR', '_', 'https', 't', 'co', 'ZOZOSe1CqQ', 'immigration', 'integration', 'canada', 'https', 't', 'co', 'M5cKGyvV8F']\n"
     ]
    }
   ],
   "source": [
    "data = \"Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada. #cdnpoli #LPC #CPCLDR��_ https://t.co/ZOZOSe1CqQ \\n #immigration #integration #canada https://t.co/M5cKGyvV8F\"\n",
    "print(match_tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Fraudster', 'Monsef', 'avoiding', 'deportation', 'from', 'Canada.', '#cdnpoli', '#LPC', '#CPCLDR��_', 'https://t.co/ZOZOSe1CqQ', '#immigration', '#integration', '#canada', 'https://t.co/M5cKGyvV8F']\n"
     ]
    }
   ],
   "source": [
    "data = \"Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada. #cdnpoli #LPC #CPCLDR��_ https://t.co/ZOZOSe1CqQ \\n #immigration #integration #canada https://t.co/M5cKGyvV8F\"\n",
    "print(whitespace_tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Fraudster', 'Monsef', 'avoiding', 'deportation', 'from', 'Canada', '.', '#', 'cdnpoli', '#', 'LPC', '#', 'CPCLDR', '��', '_', 'https', '://', 't', '.', 'co', '/', 'ZOZOSe1CqQ', '#', 'immigration', '#', 'integration', '#', 'canada', 'https', '://', 't', '.', 'co', '/', 'M5cKGyvV8F']\n"
     ]
    }
   ],
   "source": [
    "data = \"Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada. #cdnpoli #LPC #CPCLDR��_ https://t.co/ZOZOSe1CqQ \\n #immigration #integration #canada https://t.co/M5cKGyvV8F\"\n",
    "print(punct_tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Fraudster', 'Monsef', 'avoiding', 'deportation', 'from', 'Canada', '.', '#', 'cdnpoli', '#', 'LPC', '#', 'CPCLDR��_', 'https', ':', '//t.co/ZOZOSe1CqQ', '#', 'immigration', '#', 'integration', '#', 'canada', 'https', ':', '//t.co/M5cKGyvV8F']\n"
     ]
    }
   ],
   "source": [
    "data = \"Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada. #cdnpoli #LPC #CPCLDR��_ https://t.co/ZOZOSe1CqQ \\n #immigration #integration #canada https://t.co/M5cKGyvV8F\"\n",
    "print(word_tokenize(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"Neural network models have shown their promising opportunities for multi-task \\nlearning, which focus on learning the shared layers to extract the common and\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neural', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi', 'task', 'learning', 'which', 'focus', 'on', 'learning', 'the', 'shared', 'layers', 'to', 'extract', 'the', 'common', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(match_tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neural', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi-task', 'learning,', 'which', 'focus', 'on', 'learning', 'the', 'shared', 'layers', 'to', 'extract', 'the', 'common', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(whitespace_tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neural', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi', '-', 'task', 'learning', ',', 'which', 'focus', 'on', 'learning', 'the', 'shared', 'layers', 'to', 'extract', 'the', 'common', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(punct_tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neural', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi-task', 'learning', ',', 'which', 'focus', 'on', 'learning', 'the', 'shared', 'layers', 'to', 'extract', 'the', 'common', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"<br />it&#039;s very good to letting ask questions and explain again with suitable examples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['br', 'it', '039', 's', 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples']\n"
     ]
    }
   ],
   "source": [
    "print(match_tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<br', '/>it&#039;s', 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples.']\n"
     ]
    }
   ],
   "source": [
    "print(whitespace_tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<', 'br', '/>', 'it', '&#', '039', ';', 's', 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', '.']\n"
     ]
    }
   ],
   "source": [
    "print(punct_tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<', 'br', '/', '>', 'it', '&', '#', '039', ';', 's', 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
